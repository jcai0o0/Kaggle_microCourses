{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nRun the following cell to load your data and some utility functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nreviews = pd.read_csv(\"../input/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n\nfrom learntools.core import binder; binder.bind(globals())\nfrom learntools.pandas.renaming_and_combining import *\nprint(\"Setup complete.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\n\nView the first several lines of your data by running the cell below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.\n`region_1` and `region_2` are pretty uninformative names for locale columns in the dataset. Create a copy of `reviews` with these columns renamed to `region` and `locale`, respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\nrenamed = reviews.rename(columns={'region_1':'region', 'region_2':'locale'})\n\n# Check your answer\nq1.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.\nSet the index name in the dataset to `wines`."},{"metadata":{"trusted":true},"cell_type":"code","source":"reindexed = reviews.rename_axis('wine', axis='rows')\n\n# Check your answer\nq2.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reindexed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.\nThe [Things on Reddit](https://www.kaggle.com/residentmario/things-on-reddit/data) dataset includes product links from a selection of top-ranked forums (\"subreddits\") on reddit.com. Run the cell below to load a dataframe of products mentioned on the */r/gaming* subreddit and another dataframe for products mentioned on the *r//movies* subreddit."},{"metadata":{"trusted":true},"cell_type":"code","source":"gaming_products = pd.read_csv(\"../input/things-on-reddit/top-things/top-things/reddits/g/gaming.csv\")\ngaming_products['subreddit'] = \"r/gaming\"\nmovie_products = pd.read_csv(\"../input/things-on-reddit/top-things/top-things/reddits/m/movies.csv\")\nmovie_products['subreddit'] = \"r/movies\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a `DataFrame` of products mentioned on *either* subreddit."},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_products = pd.concat([gaming_products, movie_products])\n\n# Check your answer\nq3.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.\nThe [Powerlifting Database](https://www.kaggle.com/open-powerlifting/powerlifting-database) dataset on Kaggle includes one CSV table for powerlifting meets and a separate one for powerlifting competitors. Run the cell below to load these datasets into dataframes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"powerlifting_meets = pd.read_csv(\"../input/powerlifting-database/meets.csv\")\npowerlifting_competitors = pd.read_csv(\"../input/powerlifting-database/openpowerlifting.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both tables include references to a `MeetID`, a unique key for each meet (competition) included in the database. Using this, generate a dataset combining the two tables into one."},{"metadata":{"trusted":true},"cell_type":"code","source":"powerlifting_combined = powerlifting_meets.set_index(\"MeetID\").join(powerlifting_competitors.set_index(\"MeetID\"))\n\n# Check your answer\nq4.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"powerlifting_combined","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}